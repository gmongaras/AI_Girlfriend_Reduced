{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2d5939c-4f39-4c61-bd49-ae690b412374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.1.2 (SDL 2.0.18, Python 3.9.15)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import torch\n",
    "from torch import autocast\n",
    "from diffusers import StableDiffusionPipeline\n",
    "import numpy as np\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import gradio as gr\n",
    "import sys\n",
    "import openai\n",
    "import speech_recognition as sr\n",
    "import pygame\n",
    "from pygame import mixer\n",
    "import cv2\n",
    "from vosk import KaldiRecognizer, SetLogLevel\n",
    "from vosk import Model as vosk_Model\n",
    "from pydub import AudioSegment\n",
    "import wave\n",
    "import json\n",
    "from Img_Mover.Img_Mover import Img_Mover\n",
    "from Girlfriend_Obj import Girlfriend_Obj\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocess\n",
    "import gradio as gr\n",
    "import time\n",
    "from copy import deepcopy\n",
    "import asyncio\n",
    "import threading\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03df0bb9-e3d7-4ccc-b7f4-2b01a399d9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Path to the custom audio model\n",
    "# audio_model_path = \"Audio_Generation/Generation_Scripts/saved_models/default\"\n",
    "\n",
    "# # Path to the custom audio data\n",
    "# audio_data_path = \"Audio_Generation/Generation_Scripts/data/albedo\"\n",
    "\n",
    "# Path to the custom model to load in\n",
    "custom_model_path = \"CustomModel/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af919ccc-e80a-4bb5-972c-cf7839aa2a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # The initial summary is initially a basic prompt telling GPT-3 who it is\n",
    "# initial_summ = \"You are my female waifu girlfriend who loves me.\"\n",
    "# # The initial prompt tells GPT-3 how to respond\n",
    "# initial_prompt = \"Me: Hi\\nYou: Hello\\n\\n\"\\\n",
    "#     \"Me: How are you?\\nYou: Good. How are you?\\n\\n\"\\\n",
    "#     \"Me: I'm good.\\nYou: Nice to meet you.\\n\\n\"\n",
    "\n",
    "initial_summ = \"The following is a conversation with me and my waifu girlfriend\\n\\n\"\n",
    "initial_prompt = \"Me: Hello\\nGirlfriend: Hello\\n\"\\\n",
    "         \"Me: How are you?\\nGirlfriend: I am good\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ff61892-4280-46a4-a0fc-b9ed63744e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing image model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bb0cd1904c744b784d837e68e309ba8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 15 files:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image model initialized!\n",
      "Initializing custom text model\n",
      "Custom text model initialized!\n",
      "Initializing summarizer...\n",
      "Summarizer initialized!\n",
      "Not loading custom audio model\n",
      "Initializing custom image movement module\n",
      "Image movement module initialized!\n"
     ]
    }
   ],
   "source": [
    "# Setup function to setup the environment\n",
    "# memory_file = \"config_file.json\"\n",
    "memory_file = None\n",
    "MyGirlfriend = Girlfriend_Obj(initial_summ, initial_prompt, False, custom_model_path=custom_model_path, saved_memory=memory_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db9b996-8fa0-4982-8053-c4b39a576a56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77dd0bcd-a26b-4ca8-8aae-74a755c6f0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device must be cuda\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c31da8c-58d0-4aa2-aabc-a25d3d2472a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def audio_auto_submit(custom_audio, custom_model, text, audio_pth, GPT_key):\n",
    "    if audio_pth != None:\n",
    "        return MyGirlfriend.generate_audio(custom_audio, custom_model, text, audio_pth, GPT_key)\n",
    "    return MyGirlfriend.last_text\n",
    "\n",
    "# Initialize the audio mixer\n",
    "mixer.init()\n",
    "mixer.music.unload()\n",
    "    \n",
    "# Handle changes to the motion switch which either turns on or\n",
    "# off image motion\n",
    "def handle_motion_switch(switch_value):\n",
    "    MyGirlfriend.add_movement = switch_value\n",
    "    \n",
    "    # Ensure the image is in the default position\n",
    "    MyGirlfriend.img_anim.pose *= 0\n",
    "        \n",
    "    # Force a reload in the image\n",
    "    MyGirlfriend.force_gen = True\n",
    "    \n",
    "# Handles file uploads\n",
    "def upload_file(file):    \n",
    "    # Load the image as a PIL object\n",
    "    image = Image.open(file.name)\n",
    "    \n",
    "    # When an image is generated, load it in the animator\n",
    "    old_add_movement = MyGirlfriend.add_movement\n",
    "    MyGirlfriend.add_movement = False\n",
    "    MyGirlfriend.img_anim.load_new_image(img=image)\n",
    "    MyGirlfriend.add_movement = old_add_movement\n",
    "    \n",
    "    # Save the image in case of errors\n",
    "    MyGirlfriend.last_image = image\n",
    "    \n",
    "    # Ensure the image style vector is reset\n",
    "    MyGirlfriend.img_anim.pose *= 0\n",
    "    \n",
    "    # Force the image to be regenerated\n",
    "    MyGirlfriend.force_gen = True\n",
    "    \n",
    "    return file.name\n",
    "    \n",
    "# Handles image saving\n",
    "def save_img():\n",
    "    if not os.path.exists(\"saved_images\"):\n",
    "        os.mkdir(\"saved_images\")\n",
    "    filename = fr\"./saved_images/{time.ctime().replace(' ', '-').replace(':', '.')}.png\"\n",
    "    if type(MyGirlfriend.last_image) is not PIL.Image.Image:\n",
    "        Image.fromarray(MyGirlfriend.last_image.clip(0, 255).astype(np.uint8)).save(filename)\n",
    "    else:\n",
    "        MyGirlfriend.last_image.save(filename)\n",
    "        \n",
    "# Function used to test the mouth movement\n",
    "def test_mouth():\n",
    "    # Make sure the mouth isn't already moving\n",
    "    if MyGirlfriend.generating_mouth_movement == True:\n",
    "        return\n",
    "    \n",
    "    # Make sure the thread is not running\n",
    "    if MyGirlfriend.m_thread is not None:\n",
    "        MyGirlfriend.m_thread.join()\n",
    "    \n",
    "    # Start the mouth movement loop\n",
    "    MyGirlfriend.m_thread = threading.Thread(target=MyGirlfriend.run_talk_loop, args=(\"test_audio.mp3\",))\n",
    "    MyGirlfriend.m_thread.start()\n",
    "    \n",
    "# Loads a memory file into the model\n",
    "def load_mem(file):\n",
    "    # Get the filename\n",
    "    filename = file.name\n",
    "    \n",
    "    # Load in the file and upload the memory\n",
    "    outTxt = MyGirlfriend.load_mem(filename)\n",
    "    \n",
    "    return filename, outTxt\n",
    "    \n",
    "\n",
    "interface = gr.Blocks(css=\"#color_red {background-color: #f44336}\")\n",
    "with interface:\n",
    "    with gr.Tabs():\n",
    "        with gr.TabItem(\"Intro\"):\n",
    "            gr.Textbox(\"\"\"\n",
    "            Below is an intro explaining how this app works...\n",
    "            \n",
    "            Generation Tab:\n",
    "              Before starting, make sure to click the \"Setup interface\" button to setup the inferface and to begin using the app.\n",
    "              \n",
    "              The upper-most part of the interface includes two tabs: \"Voice-based Chat\" and \"Text-based Chat\" which are used to repond to the AI. Voice-based allows you to use your mic to talk to the AI while text-based allows you to chat with the AI using text. The audio is auto-submitted for response while the text requires either pressing the \"enter\" key or clicking the \"Generate Audio\" button.\n",
    "              \n",
    "              The next part is the \"Response\" text field. The latest response the AI gave will appear here.\n",
    "              \n",
    "              Below reponse is a section split into two parts. The left-most part is the currently generated image. The rightmost section has multiple parts:\n",
    "              1. \"Add motion to image?\" checkbox is used to toggle image animation. If checked, the image will be animated. The animation includes blinking and mouth movement assuming the image is in the correct form.\n",
    "              2. \"Mouth movement test\" can be used to check if mouth movement works for the current image.\n",
    "              3. \"Save current image\" saves the currently generated image to a folder named \"saved_images\". The filename will be the current time and date so that images don't overwrite eachother\n",
    "              4. \"Upload an image\" is used to upload an image you want to load in as opposed to generating one until one looks good. Clikcing on this button allows you to select the image you want to display.\n",
    "              \n",
    "              At the bottom of this section, there are two buttons: \"Generate Audio\" and \"Generate Image\". \"Generate Audio\" takes the currently entered text and generates a new response from the AI. \"Generate Image\" is used to generate a new image and display it.\n",
    "                 \n",
    "              Some notes about image animation:\n",
    "                The image must be in the correct form to be animated correctly. The image should be a face-shot photo to ensure that blinking is done correctly. Mouth movement will occur if the image is face forward and when audio is generated. Sometimes the mouth movement doesn't work and if this is the case, you should probably just generate an image until movement works.\n",
    "            \n",
    "            \n",
    "            Settings Tab:\n",
    "              The settings tab has several uses from loading in past memories to changing the style of the image to generate.\n",
    "              \n",
    "              The first block in this tab is the \"Use custom chat model?\" checkbox. If this box is checked, a free custom model will be used to respond. Otherwise GPT-3 will respond. If the box is unchecked, an OpenAI key is required which can obtained following this article: https://elephas.app/blog/how-to-create-openai-api-keys-cl5c4f21d281431po7k8fgyol0 If a key isn't provided, an error will be shown in place of the response text.\n",
    "              \n",
    "              The next block is the \"Settings\" blocks which is used to setup the style of the image and how it's generated. Settings can be found at the following link (though do be warned, the site has some sus images, not my doing btw): https://danbooru.donmai.us/wiki_pages/tag_group:image_composition\n",
    "              \n",
    "              The next block is \"Characteristics\" which is also used to style the generated images. These prompts are more of how you want the generated image to look like. Should it be female or male? What color hair?\n",
    "              \n",
    "              The \"settings\" block and \"characteristics\" block actually have no difference when implemented, but it's nice to break up the difference between image settings and image characteristics.\n",
    "              \n",
    "              The next block is the \"Guidance value\" which is used as a tradeoff between Fidelity (how good the image looks) and variance (kind of how creative the model is). A value of 1 is required, and having a value too high will cause garbage to be produced. Keeping this value around 10 seems to work well.\n",
    "              \n",
    "              The \"blink time\" button and field allows you to change the number of seconds it takes to make a full blink.\n",
    "              \n",
    "              The next part is a memory loading system. As the conversation goes on, the conversation is saved to a memory file called \"config_file.json\". This file can be loaded back in through this section of the settings to replace the current conversation with a past one saved in a .json file. The text box next to the upload button signals where the upload was a success or a failure.  \n",
    "              \n",
    "              The last part is a reset button to reset the current memory to the initial prompt.\n",
    "            \"\"\")\n",
    "        \n",
    "        with gr.TabItem(\"Generation\"):\n",
    "            gen_col = gr.Column(visible=False)\n",
    "            with gen_col:\n",
    "                # Talking to the AI\n",
    "                with gr.Tabs():\n",
    "                    with gr.TabItem(\"Voice-based Chat\"):\n",
    "                        audio = gr.Audio(source=\"microphone\", type=\"filepath\", label=\"Response\", live=True)\n",
    "                    with gr.TabItem(\"Text-based Chat\"):\n",
    "                        text = gr.Textbox(label=\"Text\", value=\"I love you!\", interactive=True)\n",
    "                response = gr.Textbox(label=\"Response\", value=\"\", interactive=False)\n",
    "\n",
    "                with gr.Row():\n",
    "                    # Note gallery expects a 3-D array: (L, W, 3)\n",
    "                    gallery = gr.Image(label=\"Generated images\", show_label=False)\\\n",
    "                        .style(height=512)\n",
    "\n",
    "                    with gr.Column():\n",
    "                        # Switch to generate a new image with audio or keep the\n",
    "                        # image static\n",
    "                        motion_switch = gr.Checkbox(value=True, label=\"Add motion to image?\")\n",
    "                        motion_switch.change(fn=handle_motion_switch, inputs=[motion_switch], outputs=[])\n",
    "\n",
    "                        # Button to test mouth movement\n",
    "                        btn_mouth_test = gr.Button(\"Mouth movement test\")\n",
    "                        btn_mouth_test.click(fn=test_mouth, inputs=[], outputs=[])\n",
    "\n",
    "                        # Button to save the currently generated image\n",
    "                        btn_save_img = gr.Button(\"Save Current Image\")\n",
    "                        btn_save_img.click(fn=save_img, inputs=[], outputs=[])\n",
    "\n",
    "                        # Button to load an image\n",
    "                        upload_button = gr.UploadButton(\"Upload an image\", file_types=[\"image\"], file_count=\"single\")\n",
    "                        upload_button.upload(fn=upload_file, inputs=[upload_button])\n",
    "\n",
    "                with gr.Row():\n",
    "                    # Button to generate new audio\n",
    "                    btn_audio = gr.Button(\"Generate Audio\")\n",
    "\n",
    "                    # Button to generate new audio\n",
    "                    btn_img = gr.Button(\"Generate Image\")\n",
    "            \n",
    "            # Button to load and setup the generation tab\n",
    "            btn_load = gr.Button(\"Setup interface\")\n",
    "            btn_load.click(fn=MyGirlfriend.event_loop, inputs=[], outputs=[gallery, gen_col, btn_load], queue=True)\n",
    "            \n",
    "            \n",
    "        with gr.TabItem(\"Settings\"):\n",
    "            # Switched for which model to use\n",
    "            custom_model = gr.Checkbox(value=True, label=\"Use custom chat model? (False to use GPT, True to use custom model)\")\n",
    "            GPT_key_ = gr.Textbox(label=\"Key to use GPT-3 (if using GPT-3)\\nNote: If you don't have one go here: https://elephas.app/blog/how-to-create-openai-api-keys-cl5c4f21d281431po7k8fgyol0\", value=\"\", interactive=True)\n",
    "            custom_audio = gr.Checkbox(value=False, label=\"Use custom audio model?\")\n",
    "\n",
    "            # Settings for the image\n",
    "            settings = gr.Textbox(label=\"Settings\", value= \"1girl,solo focus,very wide shot,feamle focus,ratio:16:9,detailed,looking at viewer,facing viewer,facing forward,vtuber\", interactive=True)\n",
    "            characteristics = gr.Textbox(label=\"Characteristics\", value=\"waifu,female,brown hair,blue eyes,sidelocks,slight blush,happy\", interactive=True)\n",
    "            guidance_scale = gr.Number(label=\"Guidance value - Tradeoff between creativity and image fidelity (greater than 1.0)\", value=10.0, interactive=True, precision=1)\n",
    "            with gr.Row():\n",
    "                blink_time = gr.Number(label=\"Time for a full blink (in seconds) (limited between 0.5 and 2.0)\", value=0.6, interactive=True, precision=2)\n",
    "                blink_time_btn = gr.Button(value=\"Change blink time\").click(MyGirlfriend.change_blink_time, inputs=[blink_time])\n",
    "                blink_time.submit(MyGirlfriend.change_blink_time, inputs=[blink_time])\n",
    "            \n",
    "            # Used to load a memory file\n",
    "            with gr.Column():\n",
    "                with gr.Row():\n",
    "                    trash_file_output = gr.File(visible=False)\n",
    "                    mem_load_btn = gr.UploadButton(\"Load memory file\", file_types=[\"json\"], file_count=\"single\")\n",
    "                    mem_file_success = gr.Textbox(label=\"Was the load successful?\", value= \"\", interactive=False)\n",
    "                    mem_load_btn.upload(fn=load_mem, inputs=[mem_load_btn], outputs=[trash_file_output, mem_file_success])\n",
    "            \n",
    "            # Used to treset the memory of the model\n",
    "            reset_btn = gr.Button(value=\"Reset Memory\", elem_id=\"color_red\")\n",
    "            reset_btn.click(MyGirlfriend.reset_memory, inputs=[], outputs=[])\n",
    "            \n",
    "        # When the audio is changed, we want to auto submit it\n",
    "        audio.change(fn=audio_auto_submit, inputs=[custom_audio, custom_model, text, audio, GPT_key_], outputs=[response])\n",
    "        \n",
    "        # When the button or text is submitted, we want to generate new audio\n",
    "        btn_audio.click(fn=MyGirlfriend.generate_audio, inputs=[custom_audio, custom_model, text, audio, GPT_key_], outputs=[response])\n",
    "        text.submit(fn=MyGirlfriend.generate_audio, inputs=[custom_audio, custom_model, text, audio, GPT_key_], outputs=[response])\n",
    "        \n",
    "        # When the image button is clicked, we want to generate a new image\n",
    "        btn_img.click(fn=MyGirlfriend.generate_img, inputs=[settings, characteristics, guidance_scale], outputs=[])\n",
    "\n",
    "interface.queue(concurrency_count=3).launch(debug=False, share=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7bc2f3-e10f-4c2a-a043-41d1985bf0c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
